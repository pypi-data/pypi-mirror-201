{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3cef5021-4f26-43dd-b761-70632793e32e",
   "metadata": {},
   "source": [
    "# Detector noise\n",
    "\n",
    "During training, simulated noise $n_I$ is added to waveforms $h_I(\\theta)$ measured in detectors to produce realistic simulated data,\n",
    "\n",
    "$$\n",
    "d_I = h_I(\\theta) + n_I.\n",
    "$$\n",
    "\n",
    "Dingo assumes this noise to be stationary and Gaussian, thus it is independent in each frequency bin, with variance given by some power spectral density (PSD).\n",
    "```{important}\n",
    "Similar to extrinsic parameters, detector noise is repeatedly sampled **during training** and added to the simulated signal. This augments the training set with new noise realizations for each epoch, reducing overfitting. \n",
    "```\n",
    "\n",
    "Although noise is *mostly* stationary and Guassian during an LVK observing run, the PSD in each detector does tend to drift from event to event. In a usual likelihood-based PE run, this is taken into account by estimating the PSD at the time of the event (either using [Welch's method](https://en.wikipedia.org/wiki/Welch%27s_method) on signal-free data surrounding the event, or at the same time as the event using [BayesWave](https://git.ligo.org/lscsoft/bayeswave)), and using this in the likelihood integral.\n",
    "\n",
    "Dingo also estimates the PSD just prior to an event and uses this at inference time in two ways:\n",
    "1. It whitens the data with respect to this PSD.\n",
    "2. It provides the PSD (or rather, the inverse ASD) as context to the neural network.\n",
    "\n",
    "A suitably trained model can therefore make use of the PSD as needed to generate the posterior.\n",
    "\n",
    "(asd-dataset)=\n",
    "## ASD dataset\n",
    "\n",
    "To train a model to perform inference conditioned on the noise PSD, it is necessary to not just sample random noise realizations for a given PSD, but also **sample the PSD** from a distribution for a given observing run. Training in this way is necessary to perform fully amortized inference and account for the variation of PSDs from event to event.\n",
    "\n",
    "The `ASDDataset` class stores a set of ASD samples for several detectors, allowing for sampling during training.\n",
    "\n",
    "```{eval-rst}\n",
    ".. autoclass:: dingo.gw.ASD_dataset.noise_dataset.ASDDataset\n",
    "    :members:\n",
    "    :inherited-members:\n",
    "    :show-inheritance:\n",
    "```\n",
    "\n",
    "As with the noise realizations, a random ASD is chosen from the dataset when preparing each sample during training. This augments the training set compared to fixing the noise ASD for each sample prior to training.\n",
    "\n",
    "Similarly to the `WaveformDataset`, the `ASDDataset` is just a container. Dingo includes routines for building such a dataset from observational data.\n",
    "\n",
    "## Command-line scripts\n",
    "\n",
    "### `dingo_generate_asd_dataset`\n",
    " The basic approach is as follows:\n",
    "1. Identify stretches of data within an observing run meeting certain criteria (sufficiently long, without events, and sufficiently high quality, ...) or take-in user-specified stretches.\n",
    "2. Fetch data corresponding to these stretches using either\n",
    "    - [GWOSC](https://www.gw-openscience.org)\n",
    "    - channels, optionally specified in the settings file.\n",
    "3. Estimate ASDs using Welch's method on these stretches.\n",
    "4. Save the collection of ASDs.\n",
    "\n",
    "```text\n",
    "usage: dingo_generate_asd_dataset [-h] --data_dir DATA_DIR [--settings_file SETTINGS_FILE] [--time_segments_file TIME_SEGMENTS_FILE] [--out_name OUT_NAME] [--verbose]\n",
    "\n",
    "Generate an ASD dataset based on a settings file.\n",
    "\n",
    "optional arguments:\n",
    "  -h, --help            show this help message and exit\n",
    "  --data_dir DATA_DIR   Path where the PSD data is to be stored. Must contain a 'settings.yaml' file.\n",
    "  --settings_file SETTINGS_FILE\n",
    "                        Path to a settings file in case two different datasets are generated in the same directory\n",
    "  --time_segments_file TIME_SEGMENTS_FILE\n",
    "                        Optional file containing a dictionary of a list of time segments that should be used for estimating PSDs.This has to be a pickle file.\n",
    "  --out_name OUT_NAME   Path to resulting ASD dataset\n",
    "  --verbose\n",
    "\n",
    "```\n",
    "where the settings file is of the form\n",
    "```yaml\n",
    "dataset_settings:\n",
    "  f_s: 4096\n",
    "  time_psd: 1024\n",
    "  T: 8\n",
    "  time_gap: 0\n",
    "  window:\n",
    "    roll_off: 0.4\n",
    "    type: tukey\n",
    "  num_psds_max: 20\n",
    "  channels:\n",
    "   H1: H1:DCS-CALIB_STRAIN_C02\n",
    "   L1: L1:DCS-CALIB_STRAIN_C02\n",
    "  detectors:\n",
    "    - H1\n",
    "    - L1\n",
    "  observing_run: O2\n",
    "condor:\n",
    "  env_path: path/to/environment\n",
    "  num_jobs: 2    # per detector\n",
    "  num_cpus: 16\n",
    "  memory_cpus: 16000\n",
    "  bid: 200\n",
    "```\n",
    "\n",
    "Options correspond to the following:\n",
    "\n",
    "Sampling rate `f_s` (Hz)\n",
    ": This should be at least twice the value of `f_max` expected to be used.\n",
    "\n",
    "Data length `time_psd` (s)\n",
    ": The entire length of data from which to estimate a PSD using Welch's method. Periodigrams are calculated on segments of this, and then averaged using the `median` method.\n",
    "\n",
    "Segment length `T` (s)\n",
    ": The length of each segment on which to take the DFT and calculate a periodigram.\n",
    "\n",
    "Gap `time_gap` (s)\n",
    ": Gap between duration-`T` segments. E.g., if `T_PSD=1024`, `T=8`, `T_gap=8`, then for each PSD, 64 periodigrams are computed, each using data stretches 8 s long, with gaps of 8 s between segments. Segments would then be $[0~\\text{s}, 8~\\text{s}], [16~\\text{s}, 24~\\text{s}], \\ldots$.\n",
    "\n",
    "Window function\n",
    ": Parameters of the window function used before taking DFT of data segments.\n",
    "\n",
    "`num_psds_max` (optional)\n",
    ": If set, stop building the dataset after this number of PSDs have been estimated. This setting is useful for building a single-PSD dataset for pretraining a network.\n",
    "\n",
    "Channels 'channels (optional)\n",
    ": If set, data will be fetched from these channels, instead of using GWOSC.\n",
    "\n",
    "Detectors\n",
    ": Which detectors (H1, L1, V1, ...) to include in the dataset.\n",
    "\n",
    "Observing run\n",
    ": Which observing run to use when estimating PSDs.\n",
    "\n",
    "Condor (optional)\n",
    ": Settings for [HTCondor](https://htcondor.readthedocs.io/en/latest/index.html) useful for parallelizing the ASD estimation across condor jobs.\n",
    "\n",
    "(ref:window-factor)=\n",
    "## Data conditioning\n",
    "\n",
    "Importantly, the variance of *white* noise in each frequency bin is not 1, but rather\n",
    "\n",
    "$$\n",
    "\\sigma^2_{\\text{white}} = \\frac{w}{4\\delta f}\n",
    "$$\n",
    "\n",
    "where $\\delta f$ is the frequency resolution and $w$ is a \"window factor\".\n",
    "\n",
    "The denominator in the noise variance is seen to arise most easily in the noise-weighted inner product,\n",
    "\n",
    "$$\n",
    "(a | b) = 4 \\text{Re} \\int_{f_\\text{min}}^{f_\\text{max}} df\\, \\frac{a^\\ast(f)b(f)}{S_{\\text{n}}(f)}\n",
    "$$\n",
    "\n",
    "The window factor comes in because a window must be applied to time series data prior to taking the FFT. The windowing is assumed to reduce the power in the noise, but not affect the signal (which is localized away from the edge of the data segment). To simulate this, we add noise with variance scaled by the window factor.\n",
    "\n",
    "The noise standard deviation is stored in the property `FrequencyDomain.noise_std`. The window factor is calculated from the data conditioning settings specified in the train settings file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dde997d7-222c-4915-8208-56d55a865188",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<img src=\"Images/IMG-Wine-Alcohol_Banner.png\" alt=\"Title Banner\" style=\"display: block; margin-left: auto; margin-right: auto; width: 100%\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "---\n",
    "Die Klasse von Wein finden Sie im Notebook _\"Klassifikation von Wein\"_ heraus. Aber manchmal sind andere Eigenschaften des Weins von Interessse, die sich nicht in eine finite Anzahl von Klassen einteilen lassen. In diesem Notebook befassen wir uns daher mit der Vorhersage des Alkoholgehalts von Wein mittels Regressionsanalyse.\n",
    "\n",
    "\n",
    "<img src=\"Images/IMG-sklearn-logo.png\" alt=\"Title Banner\" style=\"float:right; display: block; margin-left: auto; margin-right: auto; width: 30%\">\n",
    "\n",
    "Dazu werden wir einige Regressionsmodelle und weitere Funktionen aus dem Python-Paket [```scikit-learn```](https://scikit-learn.org/stable/user_guide.html) (kurz: ```sklearn```) verwenden. ```Sklearn``` ist ein äußerst mächtiges Framework, das viele Methoden des Maschinenlernens mit einheitlichen Schnittstellen zur Verfügung stellt, so dass Sie schnell und einfach verschiedene Modelle ausprobieren können. Im Laufe dieses Notebooks werden Sie einige der Funktionenen und Objekte zur Regression kennenlernen. In dem Notebook _\"Klassifikation von Wein\"_ werden Sie ebenfalls mit ```sklearn``` arbeiten, allerdings mit dem Fokus auf die Methoden und Objekte zur Lösung von Klassifikationsproblemen.\n",
    "\n",
    "Grundsätzlich gilt für beide Notebooks, dass Sie immer auch in der Dokumentation und dem User's Guide von ```sklearn``` sich weitere Informationen zu den verwendeten Objekten holen sollten, um ein tieferes Verständnis für die Zusammenhänge zu erwerben.\n",
    "\n",
    "\n",
    "## Inhalt\n",
    "<table style=\"width:256; border: 1px solid black; display: inline-block\">\n",
    "  <tr>\n",
    "    <td  style=\"text-align:right\" width=64px><img src=\"Images/IMG-csv-in.png\" style=\"float:left\"></td>\n",
    "      <td style=\"text-align:left\" width=128px>\n",
    "          <a style=\"color:black; font-size:14px; font-weight:bold; text-decoration:none\" href='#import_data'>Daten importieren</a>\n",
    "      </td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td style=\"text-align:right\"><img src=\"Images/IMG-magnifying-glass.png\" style=\"float:left\"></td>\n",
    "    <td style=\"text-align:left\" width=128px><a style=\"color:black; font-size:14px; font-weight:bold; text-decoration:none\" href='#analyze_data'>Daten analysieren</a>\n",
    "      </td>\n",
    "  </tr>\n",
    "    <tr>\n",
    "    <td style=\"text-align:right\"><img src=\"Images/IMG-broom.png\" style=\"float:left\"></td>\n",
    "    <td style=\"text-align:left\" width=128px><a style=\"color:black; font-size:14px; font-weight:bold; text-decoration:none\" href='#clean_data'>Daten säubern</a>\n",
    "        </td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "    <td style=\"text-align:right\"><img src=\"Images/IMG-gears.png\" style=\"float:left\"></td>\n",
    "    <td style=\"text-align:left\" width=128px><a style=\"color:black; font-size:14px; font-weight:bold; text-decoration:none\" href='#build_model'>Modellauswahl</a>\n",
    "        </td>\n",
    "        <tr>\n",
    "    <td style=\"text-align:right\"><img src=\"Images/IMG-new-file-out.png\" style=\"float:left\"></td>\n",
    "    <td style=\"text-align:left\" width=128px><a style=\"color:black; font-size:14px; font-weight:bold; text-decoration:none\" href='#save_model'>Modell speichern</a>\n",
    "        </td>\n",
    "  </tr>\n",
    "</table>\n",
    "\n",
    "**Hinweis:** In diesem Notebook sind einige Stellen enthalten, an denen Zufallszahlen zum Einsatz kommen (z.B. die Einteilung in Trainings- und Testset). Dadurch kann es passieren, dass manche Ergebnisse für Sie nicht exakt reproduzierbar sind und das relative Ranking der verschiedenen Regressionsmodelle oder die optimalen Werte mancher Hyperparameter bei Ihnen etwas anders aussehen. Das ändert allerdings nichts an der generellen Vorgehensweise oder den Programmiermustern. \n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<a id='import_data'></a><div><img src=\"Images/IMG-csv-in.png\" style=\"float:left\"> <h2 style=\"position: relative; top: 6px; left:5px\">1. Daten importieren</h2>\n",
    "<p style=\"position: relative; top: 10px\">\n",
    "Die Daten der Weine wurden im Rahmen einer <a href='#data_source'>wissenschaftlichen Studie erhoben</a> und die genaue Bedeutung der einzelnen Merkmale können Sie in dem entsprechenden Paper nachlesen. Die gelisteten Merkmale sind:\n",
    "\n",
    "\n",
    "<table style=\"width:256; border: 1px solid black; display: inline-block\">\n",
    "    <tr>\n",
    "        <td style=\"text-align:left\"><p style=\"color:black; font-size:14px; font-weight:bold\">Fixed acidity</p>\n",
    "        </td>\n",
    "        <td style=\"text-align:left\"><p style=\"color:black; font-size:14px\"><a href=\"https://www.wein.de/de/glossar/nichtfluechtige-saeure/\">Nichtflüchtige Säure</a></p>\n",
    "        </td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td style=\"text-align:left\"><p style=\"color:black; font-size:14px; font-weight:bold\">Volatile acidity:</p>\n",
    "        </td>\n",
    "        <td style=\"text-align:left\"><p style=\"color:black; font-size:14px\"><a href=\"https://www.wein.de/de/glossar/fluechtige-saeure/\">Flüchtige Säure</a></p>\n",
    "        </td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td style=\"text-align:left\"><p style=\"color:black; font-size:14px; font-weight:bold\">Citric acid:</p>\n",
    "        </td>\n",
    "        <td style=\"text-align:left\"><p style=\"color:black; font-size:14px\"><a href=\"https://www.wein.de/de/glossar/zitronensaeure/\">Zitronensäure</a></p>\n",
    "        </td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td style=\"text-align:left\"><p style=\"color:black; font-size:14px; font-weight:bold\">Residual sugar:</p>\n",
    "        </td>\n",
    "        <td style=\"text-align:left\"><p style=\"color:black; font-size:14px\"><a href=\"https://www.wein.de/de/glossar/restzucker-oder-restsuesse/\">Restzucker</a></p>\n",
    "        </td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td style=\"text-align:left\"><p style=\"color:black; font-size:14px; font-weight:bold\">Chlorides:</p>\n",
    "        </td>\n",
    "        <td style=\"text-align:left\"><p style=\"color:black; font-size:14px\">Chloride</p>\n",
    "        </td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td style=\"text-align:left\"><p style=\"color:black; font-size:14px; font-weight:bold\">Free sulfur dioxide:</p>\n",
    "        </td>\n",
    "        <td style=\"text-align:left\"><p style=\"color:black; font-size:14px\"><a href=\"https://www.wein.de/de/glossar/schwefeln/\">Freies Schwefeldioxid</a></p>\n",
    "        </td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td style=\"text-align:left\"><p style=\"color:black; font-size:14px; font-weight:bold\">Total sulfur dioxide:</p>\n",
    "        </td>\n",
    "        <td style=\"text-align:left\"><p style=\"color:black; font-size:14px\"><a href=\"https://www.wein.de/de/glossar/schwefeln/\">Schwefeldioxid gesamt</a></p>\n",
    "        </td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td style=\"text-align:left\"><p style=\"color:black; font-size:14px; font-weight:bold\">Density:</p>\n",
    "        </td>\n",
    "        <td style=\"text-align:left\"><p style=\"color:black; font-size:14px\">Dichte</p>\n",
    "        </td>\n",
    "    </tr>\n",
    "        <tr>\n",
    "        <td style=\"text-align:left\"><p style=\"color:black; font-size:14px; font-weight:bold\">pH:</p>\n",
    "        </td>\n",
    "        <td style=\"text-align:left\"><p style=\"color:black; font-size:14px\"><a href=\"https://www.wein.de/de/glossar/ph-wert/\">pH-Wert</a></p>\n",
    "        </td>\n",
    "    </tr>\n",
    "        <tr>\n",
    "        <td style=\"text-align:left\"><p style=\"color:black; font-size:14px; font-weight:bold\">Sulphates</p>\n",
    "        </td>\n",
    "        <td style=\"text-align:left\"><p style=\"color:black; font-size:14px\">Sulfate</p>\n",
    "        </td>\n",
    "    </tr>\n",
    "        <tr>\n",
    "        <td style=\"text-align:left\"><p style=\"color:black; font-size:14px; font-weight:bold\">Alcohol:</p>\n",
    "        </td>\n",
    "        <td style=\"text-align:left\"><p style=\"color:black; font-size:14px\">Der zu bestimmende Alkoholgehalt</p>\n",
    "        </td>\n",
    "    </tr>\n",
    "        <tr>\n",
    "        <td style=\"text-align:left\"><p style=\"color:black; font-size:14px; font-weight:bold\">Quality:</p>\n",
    "        </td>\n",
    "        <td style=\"text-align:left\"><p style=\"color:black; font-size:14px\">Subjektive Qualtitätsbewertung</p>\n",
    "        </td>\n",
    "    </tr>\n",
    "    </table>   \n",
    "\n",
    "<a id='data_source'></a><b>Quelle der Daten:</b> P. Cortez, A. Cerdeira, F. Almeida, T. Matos and J. Reis. \n",
    "  Modeling wine preferences by data mining from physicochemical properties.\n",
    "  In Decision Support Systems, Elsevier, 47(4):547-553. ISSN: 0167-9236.\n",
    "\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "Uns liegen zwei Datensätze zu, von denen einer nur Rotweine und der andere nur Weißweine enthält. Für dieses Notebook wollen wir mal annehmen, dass die Farbe des Weins keinen Einfluss auf das Ergebnis hat.\n",
    "\n",
    "Die ersten Schritt sind daher der Import und die Verbindung der beiden Datensätze. Die Daten befinden sich in ```Data/winequality-red.csv``` und ```Data/winequality-white.csv```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd  # Siehe Preprocessing/Lego-Sets/Lego Sets Preprocessing.ipynb für eine Einführung in Pandas\n",
    "\n",
    "# Datensätze importieren (pandas Funktion: pd.read_csv() Achtung: Trennzeichen ist hier das Semikolon \";\"!)\n",
    "df_red = \n",
    "df_white = \n",
    "# Verbinden Sie die beiden Datensätze mit pd.concat()\n",
    "df = "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<a id='analyze_data'></a><div><img src=\"Images/IMG-magnifying-glass.png\" style=\"float:left\"> <h2 style=\"position: relative; top: 6px; left:5px\" >2. Daten analysieren</h2>\n",
    "    \n",
    "<p style=\"position: relative; top: 10px\">\n",
    "Als nächstes wollen wir uns die Daten mal näher ansehen. Benötigen wir eine Konvertierung von Merkmalen? Müssen Werte aufgefüllt werden?</p>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Beginnen wir mit ein bisschen deskriptiver Statistik (pandas-Funktion describe()):\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "Wir stellen drei wichtige Tatsachen fest:\n",
    "\n",
    "1. Es gibt insgesamt 6497 Weine, für die uns Daten vorliegen (__```count```__), zumindest gibt es so viele Einträge in jeder Spalte. Wir müssen also erfreulicherweise keine Daten auffüllen! \n",
    "2. Alle Merkmale sind rein numerisch. Wir müssen also auch keine Daten konvertieren!\n",
    "3. Die Daten sind sehr unterschiedlich skaliert, da die Mittelwerte (__```mean```__) und Standardabweichungen (__```std```__) über mehrere Größenordnungen hinweg streuen.\n",
    "\n",
    "Daher bietet es sich an, die Spalten zunächst einzeln zu standardisieren, so dass sie jeweils einen Mittelwert von 0 und eine Standardabweichung von 1 haben (auch $z$-Score Normalisierung genannt). Dadurch werden also alle Merkmale in die gleiche Größenordnung gebracht, ohne die relative Verteilung zu vereinfachen.\n",
    "\n",
    "Unser Fahrplan für die Säuberung der Daten ist also klar:\n",
    "- Kein Konvertieren oder Auffüllen nötig\n",
    "- Standardisierung der Daten empfehlenswert\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<a id='clean_data'></a><div><img src=\"Images/IMG-broom.png\" style=\"float:left\"> <h2 style=\"position: relative; top: 6px; left:5px\">3. Daten säubern</h2>\n",
    "<p style=\"position: relative; top: 10px\">\n",
    "Wie bereits oben festgestellt, müssen wir keine Konvertierungen oder Ersetzungen machen, sondern nur die Standardisierung vornehmen. </p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "Bevor wir allerdings die Standardisierung vornehmen, sollten wir zunächst die Daten in Trainings- und Testset aufteilen, damit wir nicht schon bei der Standardisierung Daten verwenden, die eigentlich vom Modell \"ungesehene\" Testdaten sein sollen. Dazu teilen wir den Datensatz zunächst in die Merkmalvektorfolge $X$ und Klassenlabel $y$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Zunächst trennen wir den gesamten Datensatz in die Merkmale und die vorherzusagende Größe\n",
    "X = df.drop(columns=['alcohol']) # Alle Spalten von df außer 'alcohol'\n",
    "y = df['alcohol'] # Nur die Spalte 'alcohol'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "Nun kommt der eigentliche Split in Train- und Testset, den wir mit Hilfe der Funktion [```traint_test_split()```](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html) aus ```scikit-learn``` vornehmen wollen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importieren Sie aus dem sklearn-Modul model_selection die Funktion train_test_split\n",
    "from PAKET.MODUL import FUNKTION\n",
    "\n",
    "# Verwenden Sie nun die Funktion train_test_split(), um ein zurückgehaltenes (Holdout) Test-Set von 20% der gesamten Daten zu erhalten\n",
    "X_train, X_test, y_train, y_test = "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "Jetzt können wir auf dem Trainingsset die Parameter für die Standardisierung bestimmen und diese auf Trainings- und Testdaten ausführen. Wir könnten dazu natürlich von Hand in jeder Spalte den Mittelwert subtrahieren und sie durch ihre Standardabweichung teilen. Eleganter geht es jedoch mit Hilfe des Objekts [```StandardScaler```](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.StandardScaler.html):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importieren Sie aus dem sklearn-Modul preprocessing das Objekt StandardScaler\n",
    "from PAKET.MODUL import OBJEKT\n",
    "\n",
    "# Instanziieren Sie ein Objekt StandardScaler()\n",
    "stdScaler = \n",
    "\n",
    "# Berechnen Sie die Standardisierungsparametr auf dem Trainingsset (!) X_train mit Hilfe der Funktion \"fit()\"\n",
    "\n",
    "# Wenden Sie die **selbe** Standardisierung mit Hilfe der Methode transform() auf die Trainings- und Testdaten an\n",
    "X_train = \n",
    "X_test = "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "---\n",
    "<a id='build_model'></a><div><img src=\"Images/IMG-gears.png\" style=\"float:left\"> <h2 style=\"position: relative; top: 6px; left:5px\">4. Modellauswahl</h2>\n",
    "<p style=\"position: relative; top: 10px\">\n",
    "Nun können wir die aus der Vorlesung bekannten Regressionsansätze der Reihe nach ausprobieren, um das optimale Modell zu finden.</p> \n",
    "    \n",
    "Der einfachste aus der Vorlesung bekannte Ansatz zur Regression des Alkoholgehalts ist die lineare Regression. Dazu existiert in ```sklearn``` das Objekt [LinearRegression](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LinearRegression.html), das eine sehr einfache Implementierung erlaubt:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importieren Sie das Objekt LinearRegression aus dem Modul linear_model im Paket sklearn\n",
    "from PAKET.MODUL import OBJEKT\n",
    "\n",
    "# Instanziieren Sie ein Modell mit den Standardparametern\n",
    "lr1_model = LinearRegression()\n",
    "# Trainieren (\"Fitten\") Sie das Modell auf den Trainingsdaten X_train mit Hilfe der Methode fit()\n",
    "lr1_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "Die Güte dieses Regressionsmodells (und auch jedes anderen Modells in ```sklearn```) auf einem beliebigen Datensatz können Sie mit der Methode [```score()```](https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsClassifier.html#sklearn.neighbors.KNeighborsClassifier.score) bestimmen. Bei Regressionsmodellen ist die standardmäßig verwendete Metrik hier das Bestimmtheitsmaß $R^2$ (siehe Vorlesung)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# R^2 im Training\n",
    "train_score_lr1 = lr1_model.score(X_train, y_train)\n",
    "# R^2 im Test\n",
    "test_score_lr1 = lr1_model.score(X_test, y_test)\n",
    "# Ausgabe der Performancemaße\n",
    "print(\"Lineare Regression 1. Ordnung - Training: R² = {:.2f} Test: R² = {:.2f}\".format(train_score_lr1, test_score_lr1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "In der Vorlesung haben Sie gelernt, dass man verschiedene Basisfunktionen $\\varphi(x)$ bei der linearen Regression annehmen kann. Auch das Objekt ```LinearRegression``` können Sie mit beliebigen Funktionen $\\varphi(x)$ verwenden. Dabei müssen Sie die durch $\\varphi(x)$ vermittelte Transformation der Merkmale selbst vornehmen und dann die neuen, transformierten Merkmale (also die Matrix $\\Phi$ in der Vorlesung) an die Fit-Methode von ```LinearRegression``` übergeben.\n",
    "\n",
    "Wir probieren das hier mal am Beispiel von einer polynomialen Basisfunktion zweiten Grades aus:\n",
    "\n",
    "\\begin{align}\n",
    "\\varphi_1(x) &= x^1 \\\\\n",
    "\\varphi_2(x) &= x^2\n",
    "\\end{align}\n",
    "\n",
    "Die Merkmale liegen in erster Ordnung ($x^1$) ja schon in den Trainingsdaten vor. Die Merkmale zweiter Ordnung ($x^2$) müssen wir nun durch spaltenweise Quadrierung der Merkmalmatrix manuell hinzufügen:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np # Für die Matrixoperationen\n",
    "\n",
    "# Die Merkmalmatrix 1. Ordnung muss um die Merkmale 2. Ordnung ergänzt werden\n",
    "X_2_train = np.concatenate([X_train, X_train ** 2], axis=1)\n",
    "\n",
    "# Verfahren Sie analog für die Testdaten\n",
    "X_2_test = np.concatenate([X_test, X_test ** 2], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "Die Merkmale 2. Ordnung sind nicht zwangsläufig mittelwertfrei und haben eine von 1 verschiedenen Varianz. Wir müssen sie also noch standardisieren:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instanziieren Sie einen neuen StandardScaler und \"fitten\" Sie es in die Trainingsdaten inklusive 2. Ordnung\n",
    "stdScaler_2 = StandardScaler().fit(X_2_train)\n",
    "\n",
    "# Standardisieren Sie die Trainings- und Testdaten zweiter Ordnung\n",
    "X_2_train = stdScaler_2.transform(X_2_train)\n",
    "X_2_test = stdScaler_2.transform(X_2_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "Nun können wir also ein Regressionsmodell für die Merkmale bis zur Ordnung 2 trainieren:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instanziieren Sie ein Modell mit den Standardparametern\n",
    "lr2_model = \n",
    "# Trainieren (\"Fitten\") Sie das Modell auf den Trainingsdaten X_2_train mit Hilfe der Methode fit()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# R^2 im Training\n",
    "train_score_lr2 = \n",
    "# R^2 im Test\n",
    "test_score_lr2 = \n",
    "# Ausgabe der Performancemaße\n",
    "print(\"Lineare Regression 2. Ordnung - Training: R² = {:.2f} Test: R² = {:.2f}\".format( XXX, YYY ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "Aha, die Vorhersage hat sich deutlich verbessert! Allerdings haben wir nun natürlich auch mehr Prädiktoren verwendet, was grundsätzlich die Gefahr von Überanpassung (\"Overfitting\") erhöht. Wir berechnen also zur Kontrolle das korrigierte Bestimmtheitsmaß $R^2_\\mathrm{korr} = 1 - (1 - R^2)\\frac{N-1}{N-M-1}$ (siehe Vorlesung):\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Anzahl der Stichprobenelemente\n",
    "N = X_2_train.shape[0]\n",
    "# Anzahl der Prädiktoren\n",
    "M = X_2_train.shape[1]\n",
    "# Korrgiertes R^2 berechnen\n",
    "R2_korr = 1 - (1-train_score_lr2) * (N-1) / (N-M-1)\n",
    "print(\"Das korrigerte R² für die Trainingsdaten beträgt {:.2f}.\".format(R2_korr))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "Da $R^2 = R^2_\\mathrm{korr}$, ist die Erhöhung der Anzahl der Prädiktoren aufgrund der großen Zahl von Beobachtungen also offenbar noch gerechtfertigt.\n",
    "\n",
    "Würde die Hinzunahme von Merkmalen in der dritten Potenz vielleicht eine noch weitere Verbesserung liefern? Probieren Sie es aus!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Die Merkmalmatrizen 2. Ordnung müssen um die Merkmale 3. Ordnung ergänzt werden\n",
    "X_3_train = \n",
    "X_3_test = \n",
    "\n",
    "# Instanziieren Sie einen neuen StandardScaler und \"fitten\" Sie es in die Trainingsdaten inklusive 3. Ordnung\n",
    "stdScaler_3 = \n",
    "\n",
    "# Standardisieren Sie die Trainings- und Testdaten dritter Ordnung\n",
    "X_3_train =\n",
    "X_3_test = \n",
    "\n",
    "# Instanziieren Sie ein Modell mit den Standardparametern\n",
    "lr3_model = \n",
    "# Trainieren (\"Fitten\") Sie das Modell auf den Trainingsdaten X_3_train mit Hilfe der Methode fit()\n",
    "\n",
    "\n",
    "# R^2 im Training\n",
    "train_score_lr3 = \n",
    "# R^2 im Test\n",
    "test_score_lr3 = \n",
    "# Ausgabe der Performancemaße\n",
    "print(\"Lineare Regression 3. Ordnung - Training: R² = {:.2f} Test: R² = {:.2f}\".format( XXX, YYY ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "**Hinweis:** Bei Regressionsmodellen höherer Ordnung verwendet man häufig nicht nur die Merkmale in der jeweiligen Potenz, sonder auch die sogenannten \"Interaktionsterme\", also die paarweisen Multiplikationen der Merkmale. Für nur zwei Merkmale $(x_1, x_2)$ würde das also das folgende Modell ergeben:\n",
    "\n",
    "$$\\hat{y} = w_0 + w_1 \\cdot x_1 + w_2 \\cdot x_1 \\cdot x_2 + w_3 \\cdot x_1^2 + w_4\\cdot x_2 + w_5\\cdot x_2^2$$\n",
    "\n",
    "Bei einer größeren Anzahl Merkmale wird die Merkmaltransformation hierzu sehr aufwändig. Darum bietet ```sklearn``` das Objekt [```PolynomialFeatures```](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.PolynomialFeatures.html) an, mit dem diese Transformation erheblich einfacher implementiert werden kann. Schauen Sie sich doch die verlinkte Dokumentation mal an und versuchen Sie die Transformation für zweite und dritte Ordnung doch mal damit zu machen!\n",
    "\n",
    "Wir fahren aber zunächst fort mit der $L^2$-regularisierten Regression, auch Ridge Regression genannt. Auch hier bietet ```sklearn``` ein Objekt [```Ridge```](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.Ridge.html). Allerdings müssen Sie diesem Objekt den Wert für ```alpha``` (in der Vorlesung $\\lambda$) explizit übergeben. Dieser Wert muss aber üblicherweise durch Kreuzvalidierung erst gefunden werden. Aus diesem Grund existiert zusätzlich das Objekt [```RidgeCV```](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.RidgeCV.html), mit dem Sie die Kreuzvalidierung (engl. crossvalidation, CV) zur Bestimmung von ```alpha``` direkt ausführen können:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importieren Sie aus dem Modul linear_model im Paket sklearn das Objekt RidgeCV\n",
    "from PAKET.MODUL import OBJEKT\n",
    "\n",
    "# Wählen Sie die Werte für den Regularisierungsparameter alpha (in Vorlesung lambda genannt), die Sie ausprobieren möchten\n",
    "alpha_candidates = np.logspace(-6, 10, 17) # üblicherweise verwendet man hier als Kandidaten eine logarithmische Spanne von Werten\n",
    "\n",
    "# Instanziieren Sie ein RidgeCV-Objekt und übergeben Sie dabei die Kandidaten für alpha\n",
    "ridge1_model = RidgeCV(alphas=alpha_candidates)\n",
    "\n",
    "# Trainieren (\"Fitten\") Sie das Modell auf den Trainingsdaten\n",
    "ridge1_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "Wie Sie sehen, wiederholt sich das Programmiermuster im Vergleich zu ```LinearRegression``` stark, obwohl Sie ein anderes Modell verwenden. Nach dem Training gibt Ihnen RidgeCV das optimal regularisierte Modell zurück. Der gefundene optimale Wert für ```alpha``` kann über den Parameter ```alpha_``` des Objekts ausgelesen werden:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimales alpha\n",
    "alpha_opt = ridge1_model.alpha_\n",
    "# R^2 im Training\n",
    "train_score_ridge1 = ridge1_model.score(X_train, y_train)\n",
    "# R^2 im Test\n",
    "test_score_ridge1 = ridge1_model.score(X_test, y_test)\n",
    "# Ausgabe der Performancemaße\n",
    "print(\"Ridge Regression 1. Ordnung (alpha={:.2f}): Training R^2 = {:.2f} Test R^2 = {:.2f}\".format(alpha_opt, train_score_ridge1, test_score_ridge1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "Verfahren Sie analog für die Merkmale bis zur Ordnung 2 und 3:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instanziieren Sie ein RidgeCV-Objekt und übergeben Sie dabei die Kandidaten für alpha\n",
    "ridge2_model = \n",
    "\n",
    "# Trainieren (\"Fitten\") Sie das Modell auf den Trainingsdaten\n",
    "\n",
    "\n",
    "# Optimales alpha\n",
    "alpha_opt = \n",
    "# R^2 im Training\n",
    "train_score_ridge2 = \n",
    "# R^2 im Test\n",
    "test_score_ridge2 = \n",
    "# Ausgabe der Performancemaße\n",
    "print(\"Ridge Regression 2. Ordnung (alpha={:.2f}): Training R^2 = {:.2f} Test R^2 = {:.2f}\".format(XXX, YYY, ZZZ))\n",
    "\n",
    "# Instanziieren Sie ein RidgeCV-Objekt und übergeben Sie dabei die Kandidaten für alpha\n",
    "ridge3_model = \n",
    "\n",
    "# Trainieren (\"Fitten\") Sie das Modell auf den Trainingsdaten\n",
    "\n",
    "\n",
    "# Optimales alpha\n",
    "alpha_opt = \n",
    "# R^2 im Training\n",
    "train_score_ridge3 = \n",
    "# R^2 im Test\n",
    "test_score_ridge3 = \n",
    "# Ausgabe der Performancemaße\n",
    "print(\"Ridge Regression 3. Ordnung (alpha={:.2f}): Training R^2 = {:.2f} Test R^2 = {:.2f}\".format(XXX, YYY, ZZZ))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "Wir stellen fest, dass das optimale $\\lambda$ für 1. und 2. Ordnung gleich 1 beträgt, was mathematisch identisch zur unregularisierten Regression ist (siehe Vorlesung). Für die 3. Ordnung wird eine sehr starke Regularisierung als optimal identifiziert. Allerdings ist die Performance auf dem Testset trotzdem noch schlechter, als bei 2. Ordnung. Offenbar kann mit dieser Menge von Beobachtungen eine Überanpassung auch mit $L2$-Regularisierung nicht vermieden werden."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "In der Vorlesung wurde erwähnt, dass auch Support Vector Machines (SVM) für die Regression angewendet werden können. Auch wenn diese Methoden nicht Gegenstand der Vorlesung sind und ihr theoretischer Hintergrund an dieser Stelle den Rahmen sprengen würde, wollen wir sie doch ausprobieren, da sie ein sehr mächtiges Modell darstellen und durch ```sklearn```auch ohne tieferes Wissen implementierbar sind.\n",
    "\n",
    "Die (sehr stark vereinfachte) Grundidee bei der Regression mit Support Vector Machines ist, dass sich ähnlich wie bei der Klassifikation die zu findende Funktion nicht auf alle Datenpunkte stützt, sondern nur auf einige wenige Supportvektoren, durch die dann die Regressionsfunktion gelegt wird. Ein Parameter $\\epsilon$ steuert, wie viele Punkte noch berücksichtigt werden, wobei ein größeres $\\epsilon$ eine geringere Empfindlichkeit auf Ausreißer bedeutet. Auch bei der Regression können Sie den Kernel-Trick (siehe Vorlesung) anwenden und durch den Parameter $C$ regularisieren.\n",
    "\n",
    "Das Objekt zur Regression mit Support Vector Machines in ```sklearn``` heißt [```SVR```](https://scikit-learn.org/stable/modules/generated/sklearn.svm.SVR.html?highlight=svr#sklearn.svm.SVR):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importieren Sie aus dem Modul svm im Paket sklearn das Objekt SVR\n",
    "\n",
    "\n",
    "# Instanziieren eines SVR-Objekts mit Standardeinstellungen\n",
    "svr_model = \n",
    "# Trainieren Sie das Modell\n",
    "\n",
    "\n",
    "# R^2 im Training\n",
    "train_score_svr = \n",
    "# R^2 im Test\n",
    "test_score_svr = \n",
    "\n",
    "# Ausgabe der Performance\n",
    "print(\"Support Vector Regression: Training R^2 = {:.2f} Test R^2 = {:.2f}\".format(XXX, YYY))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "Wie Sie sehen, erreicht die SVR \"aus dem Stand\" ein sehr gutes Testergebnis. Allerdings lohnt es sich meistens, die Hyperparameter $C$ und $\\epsilon$ mit Hilfe von Kreuzvalidierung zu optimieren.\n",
    "\n",
    "Zur Optimierung der Hyperparameter (\"Tuning des Modells\") basierend auf Kreuzvalidierung bietet uns ```sklearn``` im Modul ```model_selection```(neben einigen anderen Varianten) das Objekt [```GridSearchCV```](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html) an. Dieses Objekt führt eine Gittersuche (engl. _grid search_) auf einem vorgebenen Parametergitter aus und überprüft an jedem Gitterknoten die Performance des so parametrisierten Modells mit Hilfe von Kreuzvalidierung (engl. _crossvalidation_, CV). Dazu benötigt es das zu tunende Regressionsmodell, das Parametergitter und weitere optionale Steuerparameter, wie die Anzahl der Folds in der Kreuzvalidierung.\n",
    "\n",
    "Die Werte der Hyperparameter, die ausprobiert werden sollen, werden in Form einer Liste von [Dictionary](https://docs.python.org/3/tutorial/datastructures.html#dictionaries) übergeben. Jedes Dictionary enthält ein Gitter, das abgesucht wird. \n",
    "\n",
    "Am Ende wird das Modell mit dem als optimal identifizierten Hyperparametersatz auf allen Folds trainiert, so dass der Rückgabewert der Methode ```fit()``` ein auch im Sinne der Hyperparameter optimales Regressionsmodell darstellt.\n",
    "\n",
    "Es empfiehlt sich sehr, die Hyperparameteroptimierung auf einem parallen Rechner auszuführen! Da jede Hyperparameterkonfiguration und jede Kreuzvalidierung unabhängig voneinander berechnet werden können, ist hier ein nahezu perfekter paralleler [Speedup](https://de.wikipedia.org/wiki/Speedup) möglich. Ein einfaches Beispiel (gilt analog für Hyperparameter in der Regression):\n",
    "\n",
    "Sie wollen prüfen, welche Zahl zwischen 1 und 10 die beste Zahl von Nachbarn in dem $k$ Nächste Nachbarn Klassifikator darstellt. Dazu müssen Sie also 10 Modelle mit 10 verschiedenen Werten für $k$ berechnen und diese miteinander vergleichen. Zum Vergleich wollen Sie jedes Modell mit 4 Folds validieren. Dazu müssen Sie also für jeden der 10 Werte von $k$ schon 4 Modell berechnen, also insgesamt 40 Trainingsvorgänge. Auf einem Single-CPU Rechner dauert dies dann zum Beispiel eine Minute. Da alle Berechnungen getrennt voneinander gemacht werden könne, kann das exakt gleiche Training auf einem Parallelrechner mit z.B. 20 CPUs in 1/20 der Zeit gerechnet werden, also in diesem Beispiel in nur 3 Sekunden. Wenn noch weitere Hyperparameter optimiert oder mehr Werte ausprobiert werden sollen, explodiert der Rechenaufwand entsprechend durch die kombinatorische Vielfalt des Gitters. Parallele Ausführung ist hier also enorm wichtig.\n",
    "\n",
    "**Achtung:** Die Dauer des Trainings ist stark abhängig von der Größe des Parameters $C$. Für kleine Werte von $C$ kann das Training schon nach wenigen Sekunden abgeschlossen sein, während es bei großen Werten durchaus mehrere Minuten dauern kann. Wundern Sie sich also nicht, wenn die Kreuzvalidierung zwischendurch \"eingefroren\" erscheint."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importieren Sie das Objekt GridSearchCV aus dem Modul model_selection im Paket sklearn\n",
    "from PAKET.MODUL import OBJEKT\n",
    "\n",
    "# Auswahl der zu testenden Hyperparameter (alle nicht spezifizierten bleiben auf dem Standardwert)\n",
    "param_grid = [\n",
    "    {'C': np.logspace(-2, 2, 5),        # Parameter C nach Vorlesung\n",
    "     'epsilon': np.logspace(-3, 3, 7),  # Parameter epsilon zur Steuerung \n",
    "     'kernel': ['linear', 'rbf']},      # Verwendeter Kernel\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "Falls Sie nicht auf dem HPC arbeiten und nicht so lange warten wollen, überspringen Sie die nächste Zelle und arbeiten Sie einfach mit den folgenden Werten für die Hyperparameter weiter:\n",
    "\n",
    "$C = 10$, $\\epsilon = 0.1$, Kernel: RBF\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instanziieren des Objekts \"GridSearchCV\"\n",
    "svr_model = GridSearchCV(SVR(),            # Regressionsmodell, das benutzt werden soll\n",
    "                         param_grid,       # Auszuprobierenden Hyperparameterwerte\n",
    "                         scoring='r2',     # Zu verwendende Metrik\n",
    "                         cv=5,             # Anzahl der Folds für die Kreuvalidierung\n",
    "                         verbose=10,       # Menge des Output während der Suche (größere Zahl -> mehr Info)\n",
    "                         n_jobs=-1)        # Anzahl der parallel genutzen CPUs; -1: alle verfügbaren CPUs nutzen\n",
    "\n",
    "# Trainieren Sie das Modell\n",
    "svr_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "Beachten Sie in der ersten Zeile der Ausgabe der Fit-Funktion die große Anzahl von zu trainierenden Modellen (\"Fits\"), die sich aus den relativ wenigen Hyperparametern ergeben haben. \n",
    "\n",
    "Die beste gefundenen Hyperparameterkombination können Sie über die Eigenschaft ```best_params_``` der Instanz von ```GridSearchCV``` auslesen:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(svr_model.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "Ob die Performance besser geworden ist, sehen wir an einem Vergleich des $R^2$ auf dem Testset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# svr_model = SVR(C=10, epsilon=0.1, kernel='rbf').fit(X_train, y_train) # Kommentieren Sie diese Zeile ein, wenn Sie die Kreuzvalidierung übersprungen haben\n",
    "\n",
    "# R^2 im Training\n",
    "train_score_svr = \n",
    "# R^2 im Test\n",
    "test_score_svr = \n",
    "\n",
    "# Ausgabe der Performance\n",
    "print(\"Tuned Support Vector Regression: Training R^2 = {:.2f} Test R^2 = {:.2f}\".format(XXX, YYY))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "Durch das Hyperparametertuning hat sich die Performance also weiter verbessert! Damit ist die SVR das beste der betrachteten Modelle. Bevor wir es für die weitere Verwendung exportieren, lohnt sich noch ein kurzer Blick auf den sogenannten Target-Response-Plot. Dabei wird in einem Streudiagramm die Zielgröße (der tatsächliche Alkoholgehalt) als unabhängige Variable gegen die Response (der vorhergesagte Alkoholgehalt) aufgetragen. Eine perfekte Regression wäre in dieser Darstellung also eine Gerade mit der Steigung 1.\n",
    "\n",
    "Zur grafischen Darstellung importieren wir zunächst ein Paket zur grafischen Darstellung von Daten. Es gibt eine Vielzahl von solchen Paketen in Python, aber wir werden hier [matplotlib](https://matplotlib.org/) verwenden."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import des Moduls zum plotten aus Matplotlib\n",
    "from matplotlib import pyplot as plt\n",
    "# Dies ist ein sog. \"Magic-Kommando\", das die Darstellung der Plots direkt im Notebook ermöglicht. \n",
    "# Wenn Sie dieses vergessen, tauchen die Plots nicht auf!\n",
    "%matplotlib inline\n",
    "\n",
    "# Vorhersagen eines Modells können Sie mit der Methode predict() generieren\n",
    "y_predicted = svr_model.predict(X_test)\n",
    "\n",
    "# Im Streudiagramm (Scatter-Plot) ide Größen gegeneinander auftragen\n",
    "plt.scatter(y_test, y_predicted)\n",
    "plt.xlabel(\"Target Alcohol\")\n",
    "plt.ylabel(\"Predicted Alcohol\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "Im Target-Response-Plot ist zwar keine perfekte Einheitsgerade zu sehen, aber die Punktwolke ist doch relativ gleichförmig verteilt und es sind keine starken Ausreißer zu sehen. Damit deckt sich der Eindruck mit dem Wert von $R^2$ im Test und es ist folglich ein gutes Ergebnis erzielt worden."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "---\n",
    "<a id='save_model'></a><div><img src=\"Images/IMG-new-file-out.png\" style=\"float:left\"> <h2 style=\"position: relative; top: 6px; left:5px\">5. Modell speichern</h2>\n",
    "<p style=\"position: relative; top: 10px\">\n",
    "Die optimal getunte Support Vector Regression ist also das beste untersuchte Modell. Wir möchten es daher abspeichern, damit für zukünftige Anwendungen nicht immer erst das Modell wieder neu trainiert werden muss.</p>\n",
    "\n",
    "Hierzu importieren wir das Modul ```pickle```und schreiben das Modell und (ganz wichtig) auch das Objekt zur Standardisierung in eine Binärdatei. Wenn wir den Standardisierer nicht auch speicher würden, könnte eine Anwenderin oder ein Anwender unseres Modells neue Daten nicht standardisieren und so keine sinnvollen Vorhersagen machen!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importieren Sie das Modul pickle\n",
    "import pickle\n",
    "\n",
    "with open('wine_alcohol_model.pickle', 'wb') as model_file:\n",
    "    # Schreiben Sie die beiden Objekte in die Datei\n",
    "    pickle.dump([svr_model, stdScaler], model_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "Wenn Sie das Modell an anderer Stelle wieder benutzen möchten, können Sie es direkt aus der Binärdatei laden:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('wine_alcohol_model.pickle', 'rb') as model_file:\n",
    "    # Entpacken Sie die Objekte aus der Datei in zwei neue Variablen\n",
    "    svr, scaler = pickle.load(model_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "Das war's!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<img src=\"Images/IMG-xkcd-ballmer.png\" alt=\"Title Banner\" style=\"display: block; margin-left: auto; margin-right: auto; width: 100%; max-width:652px\">\n",
    "Source: <a href=\"https://xkcd.com/license.html\">xkcd</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "---\n",
    "<div>Wine data from <a href=\"http://archive.ics.uci.edu/ml/datasets/Wine\">UCI Machine Learning Repository</a></div>\n",
    "<div>Icons made by <a href=\"https://www.flaticon.com/authors/swifticons\" title=\"Swifticons\">Swifticons</a> from <a href=\"https://www.flaticon.com/\" title=\"Flaticon\">www.flaticon.com</a></div>\n",
    "<div>Notebook erstellt von Yifei Li und Simon Stone</div>"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Edit Metadata",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

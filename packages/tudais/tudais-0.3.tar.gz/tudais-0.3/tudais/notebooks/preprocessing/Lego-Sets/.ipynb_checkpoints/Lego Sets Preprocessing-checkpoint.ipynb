{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": false
   },
   "source": [
    "<img src=\"Images/IMG-dirty-data.jpg\">\n",
    "Bei der Verarbeitung von Daten mit maschinellen Lernverfahren sieht man sich oft mit Datensätzen konfrontiert, die aus vielen verschiedenen Merkmalen bestehen. Diese Merkmale sind dabei oft heterogen: manche werden durch einen kontinuierlichen Zahlenwert kodiert, manche können nur bestimmte diskrete Stufen annehmen, manche sind vielleicht durch ein Wort oder sogar ganze Sätze kodiert. Oftmals fehlen auch einzelne Werte von Merkmalen, bspw. weil ein Sensor in einem multimodalen Messsystem kurzzeitig ausgefallen war oder weil bei einem Fragebogen nicht alle Fragen beantwortet wurden. Die meisten maschinellen Lernverfahren erwarten aber vollständig besetzte, ausschließlich numerische Merkmalvektoren am Eingang. \n",
    "\n",
    "<img style=\"float: right; margin:5px 0px 0px 10px\" src=\"Images/IMG-lego-logo.svg\" alt=\"Lego-Logo\" height=\"128\" width=\"128\">\n",
    "\n",
    "In diesem Notebook sollen Sie Verfahren kennenlernen und anwenden, die bei der Vorverarbeitung eines gemischten Datensatzes (\"Dirty Data\") zum Einsatz kommen können. Als Beispieldatensatz verwenden wir eine Datei, die durch Extraktion der Daten aller auf www.lego.com verfügbaren Produkte entstanden ist (siehe auch [Web Scraping](https://en.wikipedia.org/wiki/Web_scraping)). Der Inhalt der einzelnen Spalten sollte anhand der Spaltentitel weitgehend selbsterklärend sein.\n",
    "\n",
    "## Inhalt\n",
    "<table style=\"width:256; border: 1px solid black; display: inline-block\">\n",
    "  <tr>\n",
    "    <td  style=\"text-align:right\" width=64px><img src=\"Images/IMG-csv-in.png\" style=\"float:left\"></td>\n",
    "      <td style=\"text-align:left\" width=128px>\n",
    "          <a style=\"color:black; font-size:14px; font-weight:bold; text-decoration:none\" href='#import_data'>Daten importieren</a>\n",
    "      </td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td style=\"text-align:right\"><img src=\"Images/IMG-magnifying-glass.png\" style=\"float:left\"></td>\n",
    "    <td style=\"text-align:left\" width=128px><a style=\"color:black; font-size:14px; font-weight:bold; text-decoration:none\" href='#analyze_data'>Daten analysieren</a>\n",
    "      </td>\n",
    "  </tr>\n",
    "    <tr>\n",
    "    <td style=\"text-align:right\"><img src=\"Images/IMG-broom.png\" style=\"float:left\"></td>\n",
    "    <td style=\"text-align:left\" width=128px><a style=\"color:black; font-size:14px; font-weight:bold; text-decoration:none\" href='#clean_data'>Daten säubern</a>\n",
    "        </td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "    <td style=\"text-align:right\"><img src=\"Images/IMG-csv-out.png\" style=\"float:left\"></td>\n",
    "    <td style=\"text-align:left\" width=128px><a style=\"color:black; font-size:14px; font-weight:bold; text-decoration:none\" href='#save_data'>Daten speichern</a>\n",
    "        </td>\n",
    "  </tr>\n",
    "</table>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": false
   },
   "source": [
    "<a id='import_data'></a><div><img src=\"Images/IMG-csv-in.png\" style=\"float:left\"> <h2 style=\"position: relative; top: 6px\">1. Daten Importieren</h2>\n",
    "<p style=\"position: relative; top: 10px\">\n",
    "Die unbearbeiteten Rohdaten liegen im Format einer <a href=\"https://de.wikipedia.org/wiki/CSV_(Dateiformat)\">CSV-Datei</a> vor. In den meisten <a href=\"https://de.wikipedia.org/wiki/H%C3%B6here_Programmiersprache\">höheren Programmiersprachen</a> (wie z.B. Python oder Matlab) existieren bereits Methoden zum Import dieser einfach strukturierten Dateien. Im Falle von Python geht das z.B. mit der Funktion <a href=\"https://pandas.pydata.org/docs/reference/api/pandas.read_csv.html#pandas.read_csv\">read_csv()</a> aus dem Modul <a href=\"https://pandas.pydata.org/docs/user_guide/10min.html#min\">pandas (Klick hier für eine 10minütige Tour)</a>. \n",
    "</p>\n",
    "\n",
    "Das funktioniert zum Beispiel so:\n",
    "\n",
    "```python\n",
    "import pandas as pd\n",
    "data = pd.read_csv(\"Path/to/data.csv\")\n",
    "```\n",
    "\n",
    "Probieren Sie es in der nächsten Zelle gleich mal aus! Die CSV-Datei ``lego_sets.csv`` befindet sich im Unterverzeichnis ``Data``."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hier können Sie Python-Code hineinschreiben und mit Shift+Enter ausführen!\n",
    "\n",
    "# Modul importieren\n",
    "\n",
    "# CSV-Datei lesen (Daten als DataFrame speichern)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": false
   },
   "source": [
    "Sehen wir uns mal an, wie pandas die eingelesenen Daten abspeichert. Sie finden diese Information natürlich in der Dokumentation, aber Sie können auch die [Built-In Funktion type()](https://docs.python.org/3/library/functions.html#type) verwenden:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Welchen Typ hat die angelegte Datenstruktur?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": false
   },
   "source": [
    "Wie Sie nun wissen sollten, werden die Daten der Lego-Sets als [``DataFrame``](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.html#pandas.DataFrame) gespeichert.  \n",
    "Ein ``DataFrame`` ist eine tabellarische Datenstruktur in pandas, die einen geordneten Satz von Spalten enthält. Jede Spalte kann einen anderen Datentyp haben (numerisch, string, boolesch usw.). Ein ``DataFrame`` hat sowohl einen Zeilenindex als auch einen Spaltenindex.\n",
    "\n",
    "Um einen schnellen Blick auf die Datenstruktur werfen zu können, bietet pandas die Funktionen [``head()``](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.head.html) und [``tail()``](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.tail.html#pandas.DataFrame.tail), um sich die ersten oder letzten Zeilen der Struktur anzeigen zu lassen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Werfen Sie einen Blick in die Datenstruktur\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": false
   },
   "source": [
    "Sie können natürlich auch gezielt einzelne Elemente aus dem ``DataFrame`` indizieren. Das geht für ganze Spalten grundsätzlich ähnlich wie bei dem Python Standardtyp [*dictionary*](https://docs.python.org/3/tutorial/datastructures.html#dictionaries):\n",
    "\n",
    "```python\n",
    "some_dataFrame['some_column_name']\n",
    "```\n",
    "\n",
    "Wenn Sie mehrere Spalten zurückgeben wollen, können Sie dem ``[]`` Operator eine Liste der Spaltennamen übergeben:\n",
    "\n",
    "```python\n",
    "some_dataFrame[['some_column_name', 'another_column_name']]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Geben Sie alle Product IDs aus\n",
    "\n",
    "# Geben Sie nur die Bewertungssterne und die Anzahl der Reviews aus\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": false
   },
   "source": [
    "Möchten Sie (zusätzlich) die Auswahl auf einzelne Zeilen beschränken, bietet pandas die zwei Möglichkeiten ``.loc`` und ``.iloc``. Dabei ist ``.loc`` für die Verwendung mit Labels gedacht und ``.iloc`` für rein numerische Indices:\n",
    "\n",
    "```python\n",
    "some_dataFrame.loc[20:40, ['some_column_name', 'another_column_name]]\n",
    "```\n",
    "\n",
    "```python\n",
    "some_dataFrame.iloc[20:40, 2:3]\n",
    "```\n",
    "\n",
    "Die Variante mit ``.loc`` ist sehr nützlich für die Auswahl _einzelner_ Zeilen oder Spalten, während ``.iloc`` besser geeignet für die Auswahl von _Spannen_ von Zeilen oder Spalten ist.\n",
    "\n",
    "__Achtung__: Die beiden Varianten haben unterschiedliche Inklusivität der Index-Spannen!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Geben Sie 100 Zeilen von zwei beliebigen Spalten irgendwo aus dem Datensatz zurück. Vergleichen Sie .loc und .iloc!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": false
   },
   "source": [
    "Mehr zum Objekt ``DataFrame`` finden Sie unter [DataFrame](https://pandas.pydata.org/pandas-docs/stable/reference/frame.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": false
   },
   "source": [
    "<a id=\"analyze_data\"></a><div><img src=\"Images/IMG-magnifying-glass.png\" style=\"float:left\"> <h2 style=\"position: relative; top: 6px\">2. Daten analysieren</h2>\n",
    "\n",
    "<p style=\"position: relative; top: 10px\">\n",
    "Nachdem die Daten erfolgreich eingelesen wurden und wir uns über die Struktur der Daten informiert haben, können wir uns mit dem eigentlichen Inhalt befassen. Zunächst interessiert uns, in welcher Form die Daten jeder Spalte gespeichert sind. Dazu bietet ein pandas <code>DataFrame</code> das Property <code>.dtypes</code> an:\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Geben Sie den Wert des Attributs \".dtypes\" Ihres Datensatzes aus\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": false
   },
   "source": [
    "Ihnen sollte auffallen, dass einige der Spalten numerisch sind (``float64``), andere dagegen den Type ``object`` aufweisen. Da es unser Ziel ist, einen rein numerischen Datensatz zu erzeugen, müssen wir die nicht-numerischen Merkmale auf geeignete Art und Weise ersetzen bzw. konvertieren. Um den Überblick zu behalten, legen wir uns daher eine Liste mit allen Namen der zu konvertierenden Spalten an. \n",
    "\n",
    "Hierbei kann uns eine weitere Indizierungsart von ``DataFrame`` helfen: Indizierung mit einem booleschen Array. Dabei erzeugen wir ein Array von booleschen Werten, dessen Länge der Anzahl der zu indizierenden Dimension hat. Dabei steht ``True`` dafür, den Index im Aufruf zu berücksichtigen und ``False`` für die Unterdrückung des Index.\n",
    "\n",
    "```python\n",
    "some_dataFrame_with_three_columns.loc[:,[True, True, False]] # Gibt die ersten zwei Spalten des dreispaltigen DataFrame zurück\n",
    "```\n",
    "\n",
    "Dieses Array können Sie für gut lesbaren Code auch direkt im Aufruf berechnen, z.B. durch relationale Operatoren (``<>==``).\n",
    "\n",
    "Probieren Sie es gleich mal aus. Lesen Sie dazu zunächst das Attribut des ``DataFrame`` mit den Spaltentiteln aus (``.columns``). Legen Sie dann nur die Titel, für die das Attribut ``.dtypes`` den Wert ``'object'`` hat als Liste (Umwandlung mit ``list()``) ab.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Auslesen der Spaltentitel\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": false
   },
   "source": [
    "Neben ungeeigneten Typen können auch fehlende Einträge im Datensatz die nachfolgende Vearbeitung verhindern. Daher interessiert uns als nächstes, ob und wo Einträge fehlen. Pandas stellt dazu die Methode ``isna()`` bereit, die für fehlende Einträge ``True`` und für existierende Einträge ``False`` zurückgibt. Mit der Methode ``any()`` kann dann geprüft werden, ob in einer Spalte irgendwo ein Wert fehlt:\n",
    "\n",
    "```python\n",
    "some_dataFrame.isna().any()\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finden Sie die Spalten, in denen Werte fehlen.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": false
   },
   "source": [
    "Wenn in einer Spalte nur wenige Werte fehlen, können Sie möglicherweise sinnvoll aufgefüllt werden (siehe <a href=\"#clean_data\">Daten säubern</a>). Wenn allerdings sehr viele Daten fehlen, muss eventuell die ganze Spalte entfernt werden. Mit der Methode ``count()`` können alle vorhandenen Einträge jeder Spalte gezählt werden.\n",
    "\n",
    "```python\n",
    "some_dataFrame.count()\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Geben Sie die Zahl der in jeder Spalte vorhandenen Einträge zurück\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": false
   },
   "source": [
    "Setzen Sie die Zahlen nun ins Verhältnis zur Gesamtzahl der Einträge. Dazu können Sie mit dem Attribut ``shape`` zunächst ein [Tupel](https://docs.python.org/3/tutorial/datastructures.html#tuples-and-sequences) mit der Anzahl der Reihen und Spalten erzeugen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Geben Sie den relativen Anteil der vorhandenen Einträge in jeder Spalte zurück\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": false
   },
   "source": [
    "Selbst die Spalte mit den meisten fehlenden Einträgen bringt es demnach noch auf über 80 % vorhandener Einträge, was das Einfüllen der Werte ([Imputation](https://de.wikipedia.org/wiki/Imputation_(Statistik))) noch sinnvoll erscheinen lässt. Diese Entscheidung muss allerdings in jedem konkreten Problem neu abgewogen werden und hier können auch keine allgemein gültigen Richtwerte angegeben werden.\n",
    "\n",
    "Für unsere Zwecke gehen wir nun aber davon aus, dass in jeder Spalte genügend Daten vorhanden sind. Im nächsten Abschnitt werden wir nun die oben identifizierten nicht-numerischen Spalten konvertieren und die fehlenden Werte einfüllen."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": false
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": false
   },
   "source": [
    "<a id=\"clean_data\"></a><div><img src=\"Images/IMG-broom.png\" style=\"float:left\"> <h2 style=\"position: relative; top: 6px\">3. Daten säubern</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wie bereits oben beschrieben setzen die meisten maschinellen Lernverfahren lückenlose numerische Eingangsdaten voraus. Daher beginnen wir die Datenaufarbeitung zunächst mit der Konvertierung aller nicht-numerischen Spalten. Anschließend werden wir die oben identifizierten fehlenden Einträge auf möglichst geschickte Art und Weise auffüllen.\n",
    "\n",
    "__Achtung:__ Natürlich ist das Auffüllen von fehlenden Einträgen ein Eingriff und Sie __verfälschen damit die Daten!__ Trotzdem kann das eine legitime Vorgehensweise sein, wenn nicht zu viele Elemente fehlen. Eine feste Größe, was als zu viel gilt, lässt sich hier nicht angeben. Grundsätzlich sollten Sie allerdings Ihre auf aufgefüllten Daten trainierten __Modelle immer nur auf vollständigen Daten validieren und testen!__ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": false
   },
   "source": [
    "<h3> 3.1 Nicht-numerische Merkmale</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": false
   },
   "source": [
    "Wie oben bereits festgestellt, müssen wir die Daten einiger Spalten in Zahlenwerte konvertieren. Für dieses Problem gibt es kein allgemeingültiges Rezept, sondern es muss im Einzelfall überlegt werden, welche Konvertierung sinnvoll erscheint. Daher bearbeiten wir im folgenden jede Spalte einzeln."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": false
   },
   "source": [
    "<h4>3.1.1 Alter</h4>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": false
   },
   "source": [
    "Die Spalte ``ages`` besitzt den ``dtype`` ``'object'``. Das überrascht zunächst, schließlich sollte sich das Alter doch leicht numerisch kodieren lassen. Werfen wir daher nochmal einen Blick auf die ersten paar Einträge der Spalte:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Geben Sie den Kopf der Spalte 'ages' aus\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": false
   },
   "source": [
    "Ihnen fällt sicherlich auf, dass Lego das Alter branchenüblich als Intervalle angibt. Dabei verwendet der Datensatz offenbar Zeichenketten verschiedener Formate, da schon im Kopf zwei verschiedene zu sehen sind. Wie viele einzigartige Werte es gibt, kann durch die Methode ``unique()`` ausgegeben werden:\n",
    "\n",
    "```python\n",
    "some_dataFrame.unique()\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Geben Sie die möglichen Wert der Spalte 'ages' aus\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": false
   },
   "source": [
    "Wir sehen, dass das Format der Altersangabe entweder ein Mindest- _und_ ein Maximalalter beinhaltet oder _nur_ ein Mindestalter. Es bietet sich daher hier an, die Spalte ``'ages'`` durch zwei neue Spalten ``'age_min'`` und ``'age_max'`` zu ersetzen. \n",
    "\n",
    "Dabei ist jedoch noch problematisch, dass bei manchen Angaben das Maximalalter fehlt. Wir können allerdings den (ebenfalls branchentypischen) globalen Maximalwert von ``99`` hier einfüllen. Damit greifen wir also eigentlich schon vor und machen unsere erste Imputation: wir ersetzen einen fehlenden Wert durch einen statistisch gefundenen Wert: das Maximum.\n",
    "\n",
    "Ein weiteres Hindernis bei der weiteren Verarbeitung ist die Notation ``'½'``. Wir wollen daher auch diese Zeichenkennte ersetzen. __Achtung:__ ``½`` ist nicht die gleiche Zeichenkette wie ``1/2``.\n",
    "\n",
    "Wir möchten also in jedem String einer Spalte eine Zeichenkette mit einer anderen ersetzen. Das geht in pandas sehr einfach:\n",
    "\n",
    "```python\n",
    "some_dataFrame['column_label'] = some_dataFrame['column_label'].str.replace('old_string', 'new_string')\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ersetzen Sie in der Spalte 'ages' die Zeichenkette '+' mit der Zeichenkette '-99'\n",
    "\n",
    "# Ersetzen Sie außerdem in der Spalte 'ages' die Zeichenkette '½' mit der Zeichenkette '.5'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": false
   },
   "source": [
    "Jetzt haben alle Zeichenkette das gleiche Format und wir können die neuen Spalten ``'age_min'`` und ``'age_max'`` erschaffen, in dem wir die Strings in ``'ages'`` am Zeichen ``-`` aufteilen. Zum Trennen einer Zeichenkette an einem bestimmten Trennzeichen stellt pandas ``.str.split()`` bereit.\n",
    "\n",
    "```python\n",
    "split_string = some_dataFrame['column_label'].str.split('string_to_split_on', expand=True)\n",
    "```\n",
    "\n",
    "__Hinweis:__ Wenn das Argument ``expand`` nicht auf ``True`` gesetzt wird, gibt die Methode die gefundenen Teilstrings als Reihe von Tupeln zurück, was für die weitere Verarbeitung hier nicht optimal ist."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trennen Sie die Werte in 'ages' am Bindestrich '-',\n",
    "\n",
    "# und speichern Sie das erste Element in der Spalte 'age_min' \n",
    "\n",
    "# und das zweite ELement in der Spalte 'age_max'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": false
   },
   "source": [
    "Da wir nun alle Information aus der Spalte ``'ages'`` verarbeitet haben, können wir die Spalte aus dem Datensatz streichen. Hierzu können wir die Methode ``drop()`` verwenden. Mit dem Argument ``inplace=True`` wird die Spalte direkt im Datensatz gelöscht und nicht nur eine Kopie des Datensatzes ohne die Spalte zurückgegeben.\n",
    "\n",
    "```python\n",
    "some_dataFrame.drop(columns=['column_to_drop'], inplace=True)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Löschen Sie die nun überflüssige Spalte 'ages' aus dem Datensatz\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": false
   },
   "source": [
    "Zum Schluss müssen wir noch die neuen Spalten in numerische Datentypen umwandeln. Beachten Sie, dass wir zwar bereits Zahlenwerte in den Spalten stehen haben, diese aber noch als Zeichenketten repräsentiert sind. Wir können mit Hilfe von ``astype()`` leicht eine Typkonvertierung vornehmen.\n",
    "\n",
    "```python\n",
    "some_dataFrame['column_of_some_dtype'].astype('new_dtype')\n",
    "```\n",
    "\n",
    "Wie die Typkonvertierung genau passiert, entnehmen Sie bitte der Dokumentation der Methode [astype()](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.astype.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wandeln Sie die Einträge der Spalten 'age_min' und 'age_max' in den Datentyp 'float32' um\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": false
   },
   "source": [
    "#### 3.1.2 Schwierigkeitsgrad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Der Schwierigkeitsgrad ist in der Spalte ``'review_difficulty'`` abgelegt. Lassen Sie sich die einzigartigen Einträge dieser Spalte anzeigen (siehe oben)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Zeige einzigartige Einträge in 'review_difficulty'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": false
   },
   "source": [
    "Wir stellen fest, dass der Schwierigkeitsgrad zwar nicht direkt numerisch kodiert ist, aber auf einer fünfstufigen [Ordinalskala](https://de.wikipedia.org/wiki/Ordinalskala) basiert. Außerdem fehlen offenbar einige Einträge, da auch ``nan`` in der Liste dabei ist.\n",
    "\n",
    "Der Schwierigkeitsgrade könnte demnach auch auf einer Skala von 1 bis 5 abgebildet werden, wobei 'Very Easy' auf 1 und 'Very Challenging' auf 5 abgebildet werden sollte, damit 'Very Easy' < 'Very Challenging' gilt.\n",
    "\n",
    "Diese Abbildung können wir leicht mithilfe von ``map()`` vornehmen, die allerdings nur für Objekte vom Typ ```Series``` existiert. Jede Spalte eines ```DataFrame``` Objekt ist jedoch auch ein ```Series```-Objekt. Damit geht folgendes:\n",
    "\n",
    "````python\n",
    "some_dataFrame['column_name'] = some_dataFrame['column_name'].map({'key1': 'value1', 'key2': 'value2'}, na_action='ignore')\n",
    "````\n",
    "__Hinweis:__ Da wir die fehlenden Werte (``na``) noch nicht eingefüllt haben, sollte das Argument ``na_action='ignore'`` gesetzt werden, damit die ``na`` Werte einfach durchgereicht werden."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Legen Sie die Reihenfolge der Schwierigkeitgrade fest\n",
    "\n",
    "# Bilden Sie strings auf die Zahlenwerte ab\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": false
   },
   "source": [
    "Die fehlenden Einträge könnten bereits jetzt eingefüllt werden. So könnte zum Beispiel für alle fehlenden Einträge der Schwierigkeitsgrade ``'Average'`` angenommen werden. Oder man könnte den tatsächlichen, numerischen Durschnitt oder den häufigsten Wert verwenden. Es ist allerdings wahrscheinlich, dass der Schwierigkeitsgrad auch von anderen Spalten wie der Altersangabe oder der Anzahl der Teile abhängt. Daher werden die fehlenden Einträge sinnvoller Weise erst später eingefügt."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": false
   },
   "source": [
    "#### 3.1.3 Ländercode "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": false
   },
   "source": [
    "Schauen Sie sich die Werte an, die in der Spalte ``'country'`` auftreten."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Zeige einzigartige Einträge in 'country'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": false
   },
   "source": [
    "Ähnlich wie beim Schwierigkeitsgrad haben wir auch hier nur eine begrenzte Anzahl von Werte vertreten. Allerdings kann bei den Ländercodes keine sinnvolle, numerische Reihenfolge festgelegt werden. Stattdessen kann man durch sogenannte [Dummy-Variablen](https://de.wikipedia.org/wiki/Dummy-Variable) die Zugehörigkeit zu dem jeweiligen Land binär signalisieren.\n",
    "\n",
    "Pandas bietet hierfür die Funktion ``get_dummies()`` an, die die Kodierung enorm einfach gestaltet:\n",
    "\n",
    "```python\n",
    "dummy_variables = some_dataFrame['column_name'].str.get_dummies()\n",
    "```\n",
    "\n",
    "__Hinweis:__ Die Dummy-Variablen können dann mit Hilfe von [concat()](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.concat.html) an den Datensatz angehängt werden. Achten Sie darauf, die _Spalten_ zu verketten!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dummy-Variablen berechnen\n",
    "\n",
    "# An Datensatz anhängen\n",
    "\n",
    "# Spalte 'country' streichen\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": false
   },
   "source": [
    "#### 3.1.4 Name des Sets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": false
   },
   "source": [
    "Der Name des Sets stellt eine besondere Herausforderung dar, da fast jedes Set einen eigenen Namen hat. Diese Variable mit Dummy-Variablen zu kodieren würde daher die Anzahl der Variablen enorm vergrößern, was für die meisten Modelle, die mit diesen Daten arbeiten sollen, sehr ungünstig ist ([Fluch der Dimensionalität](https://de.wikipedia.org/wiki/Fluch_der_Dimensionalit%C3%A4t)). Daher sollte diese Spalte als ungeordnete, kategoriale Variable kodiert werden. Hierfür gibt es in pandas den Datentyp ``category``, zu dem wir ganz einfach konvertieren können:\n",
    "\n",
    "```python\n",
    "categorical_column = some_dataFrame['non_categorical_column'].astype('category')\n",
    "```\n",
    "\n",
    "Die kategoriale Variable kann dann wiederum in einen numerischen Typ gewandelt werden, indem wir uns den Code ausgeben lassen, der jeder Stufe der Variable zugewiesen wird:\n",
    "\n",
    "```python\n",
    "numerical_categorical_column = categorical_column.cat.codes\n",
    "```\n",
    "\n",
    "__Achtung:__ Durch diese Kodierung wird eine Rangfolge der Kategorien impliziert, die aber faktisch nicht begründbar ist."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wandeln Sie die Spalte 'set_name' in eine kategorische Variable um\n",
    "\n",
    "# Weisen Sie der Spalte 'set_name' die Codes der Kategorien der Variable zu\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": false
   },
   "source": [
    "#### 3.1.4 Name des Themas\n",
    "Auch bei der Spalte ``'theme_name'`` gibt es viele verschiedene einzigartige Werte, wenn auch nicht ganz so viele wie im Falle von ``'set_name'``. Eine Kodierung mit Dummy-Variablen kann hier den Merkmalraum bereits verhängnisvoll vergrößern. Tatsächlich sollte man in einem solchen Grenzfall die Performance der zu trainierenden Modell mit Dummy-Kodierung und kategorialer Kodierung vergleichen, um eine Entscheidung zu treffen. Da uns das hier nicht möglich ist, gehen wir einfach davon aus, dass die Dummy-Kodierung den Merkmalraum noch nicht zu hochdimensional werden lässt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Führen Sie die Dummy-Kodierung für 'theme_name' wie oben beschrieben durch\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": false
   },
   "source": [
    "#### 3.1.5 Produktbeschreibungen\n",
    "Die Produktbeschreibungen ``prod_desc`` und ``prod_long_desc`` liegen als Fließtext vor und stellen damit eine besondere Herausforderung dar. Schauen wir uns einige Beschreibungen zunächst mal an. Dabei empfiehlt es sich, nicht die ersten oder letzten paar Einträge auszuwählen, sonder eine zufällige Auswahl zu treffen. Pandas bietet dazu die Methode ``.sample()``:\n",
    "\n",
    "```python\n",
    "some_dataFrame.sample(number_of_samples)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Geben Sie 10 zufällige Einträge der Spalte 'prod_desc' aus\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": false
   },
   "source": [
    "Es scheint, dass die kurze Produktbeschreibung keine systematischen Informationen enthält. An dieser Stelle könnte man viele verschiedene Ansätze verfolgen und bspw. eine Analyse der verwendeten Verben und Adjektive vornehmen (mittels Methoden des [Natural Language Processing](https://de.wikipedia.org/wiki/Computerlinguistik)). Für den Rahmen dieses Notebooks führt das aber zu weit und wir beschränken uns stattdessen auf die Anzahl der Wörter in der Kurzbeschreibung. Dazu müssen wir die Strings zunächst an den Leerzeichen auftrennen (siehe oben) und die Anzahl der getrennten Einheiten zählen.\n",
    "\n",
    "Zur Bestimmung der Anzahl der Elemente in einem Objekt bietet Python die built-in Funktion [``len()``](https://docs.python.org/3/library/functions.html#len)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Spalten Sie die Strings in der Spalte 'prod_desc' am Leerzeichen auf\n",
    "\n",
    "# Bestimmen Sie die Anzahl der Worte (Achtung: Schleife oder besser List Comprehension und Behandlung von NaN (= 0 Wörter) nötig!)\n",
    "\n",
    "# Ersetzen sie die Spalte 'prod_desc' mit der ermittelten Anzahl\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": false
   },
   "source": [
    "Werfen wir nun einen Blick auf die ausführliche Beschreibung:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Geben Sie 10 zufällige Beispiele aus der Spalte 'prod_long_desc' aus (Achtung: hier ist eine Schleife und print() nötig, um die ganze Beschreibung sehen zu können)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": false
   },
   "source": [
    "Auch hier könnten natürlich elaborierte Analysen angesetzt werden. Wir stellen aber auch fest, dass viele Beschreibungen die physischen Abmessungen der Lego Sets beinhalten. Diese könnten leicht numerisch kodiert werden, wenn wir sie aus dem Fließtext extrahieren können. Der Einfachheit halber wollen wir nur die erste in der Beschreibung angegebene Abmessung für jede Dimension berücksichtigen.\n",
    "\n",
    "Um in einem String ein auftretendes Muster (wie z.B. \"<ZAHL><EINHEIT><LEERZEICHEN><DIMENSION>\") zu finden, eignen sich [reguläre Ausdrucke](https://de.wikipedia.org/wiki/Regul%C3%A4rer_Ausdruck). Reguläre Ausdrücke sind ein sehr mächtiges Konzept, das in vielen Programmiersprachen und -frameworks Verwendung findet. Mit einem regulären Ausdruck lassen sich auch komplexe Muster in abstrakter Weise formulieren, so dass Sie dann für einen Vergleich genutzt werden können. Ein ausführlicher Exkurs zu regulären Ausdrücken führt an dieser Stelle allerdings zu weit, weshalb wir die Ausdrücke für die zu findenen Muster bereits vorgegeben haben. Nachdem Sie ein Muster definiert haben, können Sie mit der pandas-Methode ``extract()`` das erste Auftreten des Musters extrahieren:\n",
    "    \n",
    "```python\n",
    "some_dataFrame.str.extract(regularExpression)\n",
    "```\n",
    "__Achtung:__ Da in regulären Ausdrücken viele Sonderzeichen vorkommen, werden sie in Python üblicherweise als [Raw String](https://www.journaldev.com/23598/python-raw-string) (mit einem vorangestellten ``r``) definiert.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verwenden Sie str.extract() und den String r'(?:(?P<high>\\d+)(?:” high))' um die erste Höhenangabe in Inch zu extrahieren\n",
    "\n",
    "# Die Breite finden Sie mit r'(?:(?P<wide>\\d+)(?:” wide))'\n",
    "\n",
    "# Die Länge finden Sie mit r'(?:(?P<long>\\d+)(?:” long))'\n",
    "\n",
    "# Fügen Sie die Dimensionen als neue Spalten 'height', 'width', 'length' in den DataFrame lego_data ein\n",
    "\n",
    "\n",
    "\n",
    "# Entfernen Sie die Spalte 'prod_long_desc'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": false
   },
   "source": [
    "### 3.2 Fehlende Werte"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": false
   },
   "source": [
    "Der Datensatz enthält nun ausschließlich numerische Merkmale. Allerdings sind  nicht in jeder Spalte alle Einträge vorhanden. Viele Algorithmen erwarten aber vollständige Datensätze. Der einfachste Weg, mit fehlenden Werten umzugehen, ist die betreffenden Zeilen oder Spalten einfach zu streichen. Das ist allerdings natürlich mit Informationsverlust verbunden und sollte daher vermieden werden. In diesem Abschnitt werden wir daher verschiedene Methoden verwenden, um die fehlenden Werte aufzufüllen.\n",
    "\n",
    "Schauen wir uns nochmal an, wie viele Werte in jeder Spalte jeweils fehlen (siehe oben)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Geben Sie die Anzahl der fehlenden Werte pro Spalte aus\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wir stellen fest, dass vor allem die Bewertungen (Rezensionen und Sterne-Bewertungen) unvollständig sind. Ziel des Einfüllens ist es, den Datensatz zu vervollständigen ohne dabei die Verteilung innerhalb der jeweiligen Spalte zu verzerren. Daher ist es sinnvoll, sich die jeweilige Verteilung zunächst zu betrachten, bevor das weitere Vorgehen festgelegt wird.\n",
    "\n",
    "Pandas bietet hierzu die Methode ```.hist()```, mit der Histogramme der Spalten (oder einer Auswahl von Spalten) eines Datenframes angezeigt werden können.\n",
    "\n",
    "```python\n",
    "some_dataFrame[list_of_columns_of_interest].hist()\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Geben Sie Histogramme der Spalten mit fehlenden Werten aus\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": false
   },
   "source": [
    "Wir stellen fest, dass die meisten Spalten keine Normalverteilung aufweisen. Die fehlenden Werte hier mit dem Mittelwert der Spalte aufzufüllen, wäre daher ungünstig. Stattdessen kann man bei solchen schiefen Verteilungen den häufigsten Wert einfüllen. \n",
    "\n",
    "Für die Bestimmung des häufigsten Wertes und des Mittelwertes gibt es in pandas die Methoden ```.mean()``` und ```.mode()```. Für das Auffüllen von fehlenden Werten gibt es die Methode ```.fillna()```.\n",
    "\n",
    "```python\n",
    "some_dataFrame[columns].mean() # Gibt Mittelwerte der Spalten <columns> zurück\n",
    "some_dataFrame[columns].mode() # Gibt häufigste Werte der Spalten <columns> zurück ACHTUNG: Rückgabewert ist nicht skalar!\n",
    "some_dataFrame[columns].fillna(value) # Füllt alle fehlenden Werte in den Spalten <columns> mit <value> auf\n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Füllen Sie die Spalte(n) mit (näherungsweise) normalverteilten Werte mit dem Mittelwert auf\n",
    "\n",
    "# Füllen Sie die Spalte(n) mit nicht normalverteilten Werte mit dem jeweils häufigsten Wert auf\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": false
   },
   "source": [
    "Auch hier sind durchaus andere, Problem-angepasste Möglichkeiten zum Auffüllen oft sinnvoll. Zum Beispiel könnte man den Schwierigkeitsgrad auch versuchen, aus der Anzahl der Teile vorherzusagen, und so das Auffüllen der fehlenden Werte zu einem eigenen Regressionsproblem machen. Oder man versucht zu einer Zeile, in der ein Wert fehlt, eine möglichst ähnliche Zeile zu finden und übernimmt den fehlenden Wert (Nächste Nachbarn-Methode). Das beliebte Python-Toolkit [_scikit-learn_](https://scikit-learn.org/stable/) bietet bspw. eine ganze Reihe von Möglichkeiten zur Imputation im Modul [```sklearn.impute```](https://scikit-learn.org/stable/modules/classes.html#module-sklearn.impute). Im Rahmen dieses Notebooks soll darauf aber nicht weiter eingegangen werden."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": false
   },
   "source": [
    "<a id=\"save_data\"></a><div><img src=\"Images/IMG-csv-out.png\" style=\"float:left\"> <h2 style=\"position: relative; top: 6px\">3. Daten exportieren</h2>\n",
    "\n",
    "<p style=\"position: relative; top: 10px\">\n",
    "Damit ist der Datensatz nun also vollständig und besteht nur noch aus numerischen Merkmalen. Er muss also nur noch in eine CSV-Datei exportiert werden und kann dann von Modellen zur Regression oder Klassifikation ohne weitere Verarbeitung genutzt werden.\n",
    "\n",
    "Pandas bietet auch hierfür eine einfache Methode an: ```.to_csv()```\n",
    "\n",
    "```python\n",
    "some_dataFrame.to_csv(filename)\n",
    "```\n",
    "</p>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exportieren Sie den aufgeräumten Datensatz in eine Datei namens 'tidy_lego_sets.csv' im Unterordner 'Data'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": false
   },
   "source": [
    "<p style=\"text-align:center; font-weight:bold\">Herzlichen Glückwunsch! Sie haben erfolgreich den unordentlichen Haufen Lego sortiert.</p>\n",
    "\n",
    "<img src=\"Images/IMG-lego-messy-to-tidy.png\" width=\"1080px\" style=\"float:center\"/>\n",
    "\n",
    "\n",
    "<a style=\"float:left;background-color:black;color:white;text-decoration:none;padding:4px 6px;font-family:-apple-system, BlinkMacSystemFont, &quot;San Francisco&quot;, &quot;Helvetica Neue&quot;, Helvetica, Ubuntu, Roboto, Noto, &quot;Segoe UI&quot;, Arial, sans-serif;font-size:12px;font-weight:bold;line-height:1.2;display:inline-block;border-radius:3px\" href=\"https://unsplash.com/@egnaro?utm_medium=referral&amp;utm_campaign=photographer-credit&amp;utm_content=creditBadge\" target=\"_blank\" rel=\"noopener noreferrer\" title=\"Download free do whatever you want high-resolution photos from Rick Mason\"><span style=\"display:inline-block;padding:2px 3px\"><svg xmlns=\"http://www.w3.org/2000/svg\" style=\"height:12px;width:auto;position:relative;vertical-align:middle;top:-2px;fill:white\" viewBox=\"0 0 32 32\"><title>unsplash-logo</title><path d=\"M10 9V0h12v9H10zm12 5h10v18H0V14h10v9h12v-9z\"></path></svg></span><span style=\"display:inline-block;padding:2px 3px\">Photo by Rick Mason</span></a><a style=\"float:right;background-color:black;color:white;text-decoration:none;padding:4px 6px;font-family:-apple-system, BlinkMacSystemFont, &quot;San Francisco&quot;, &quot;Helvetica Neue&quot;, Helvetica, Ubuntu, Roboto, Noto, &quot;Segoe UI&quot;, Arial, sans-serif;font-size:12px;font-weight:bold;line-height:1.2;display:inline-block;border-radius:3px\" href=\"https://www.reddit.com/r/lego/comments/7mhq2b/finished_kind_of_organizing_my_spare_lego_pieces/\" target=\"_blank\" rel=\"noopener noreferrer\" title=\"Download free do whatever you want high-resolution photos from Rick Mason\"><span style=\"display:inline-block;padding:2px 3px\"><svg xmlns=\"http://www.w3.org/2000/svg\" style=\"height:12px;width:auto;position:relative;vertical-align:middle;top:-2px;fill:white\" viewBox=\"0 0 32 32\"><title>unsplash-logo</title><path d=\"M10 9V0h12v9H10zm12 5h10v18H0V14h10v9h12v-9z\"></path></svg></span><span style=\"display:inline-block;padding:2px 3px\">Photo by rexorhun</span></a>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": false
   },
   "source": [
    "<div>Icons made by <a href=\"https://www.flaticon.com/authors/swifticons\" title=\"Swifticons\">Swifticons</a> from <a href=\"https://www.flaticon.com/\" title=\"Flaticon\">www.flaticon.com</a></div>\n",
    "<div>Notebook erstelt von Yifei Li & Simon Stone</div>"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Edit Metadata",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Integrating a New Year of FERC Form 1\n",
    "* Every September / October we integrate a new year of FERC Form 1 data.\n",
    "* This notebook contains some tools to help with that somewhat manual process."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Before you start!\n",
    "You will need:\n",
    "* An up-to-date FERC Form 1 database with all years of available data in it (**including the new year**).\n",
    "* An up-to-date PUDL database with all years of available EIA data in it (**including** the new year).\n",
    "* An up-to-date PUDL database with all years of available FERC Form 1 data in it (**NOT** including the new year)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import re\n",
    "import pandas as pd\n",
    "import sqlalchemy as sa\n",
    "import pudl\n",
    "import dbfread\n",
    "import pathlib\n",
    "import pudl.constants as pc\n",
    "\n",
    "import logging\n",
    "logger = logging.getLogger()\n",
    "logger.setLevel(logging.INFO)\n",
    "handler = logging.StreamHandler(stream=sys.stdout)\n",
    "formatter = logging.Formatter('%(message)s')\n",
    "handler.setFormatter(formatter)\n",
    "logger.handlers = [handler]\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "import seaborn as sns\n",
    "sns.set()\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mpl.rcParams['figure.figsize'] = (10,4)\n",
    "mpl.rcParams['figure.dpi'] = 150\n",
    "pd.options.display.max_columns = 100\n",
    "pd.options.display.max_rows = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pudl_settings = pudl.workspace.setup.get_defaults()\n",
    "ferc1_engine = sa.create_engine(pudl_settings['ferc1_db'])\n",
    "pudl_engine = sa.create_engine(pudl_settings['pudl_db'])\n",
    "pudl_settings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate new Row Maps\n",
    "* The FERC 1 Row Maps function similarly to the xlsx_maps that we use to track which columns contain what data across years in the EIA spreadsheets.\n",
    "* In many FERC 1 tables, a particular piece of reported data is associated not only with a named column in the database, but also what \"row\" the data showed up on.\n",
    "* So for instance, in the Plant in Service table, the column might contain \"additions\" to plant in service, while each numbered row corrresponds to an individual FERC Account to which value was added.\n",
    "* However, from year to year which row corresponds to which value (e.g. which FERC account) changes, as new rows are added, or obsolete rows are removed.\n",
    "* To keep all this straight, we look at the \"row literals\" -- the labels that are associated with each row number -- year by year.\n",
    "* Any time the row literals change between years, we compare the tables for those two adjacent years to see if the row numbers associated with a given piece of data have actually changed.\n",
    "* However, many tables are not organized this way, and in most tables that are organized this way, in most years, the rows don't change.\n",
    "* The row maps are stored in CSVs, under `src/pudl/package_data/meta/ferc1_row_maps`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_row_literals(table_name, report_year, ferc1_engine):\n",
    "    row_literals = (\n",
    "        pd.read_sql(\"f1_row_lit_tbl\", ferc1_engine)\n",
    "        .query(f\"sched_table_name=='{table_name}'\")\n",
    "        .query(f\"report_year=={report_year}\")\n",
    "        .sort_values(\"row_number\")\n",
    "    )\n",
    "    return row_literals\n",
    "\n",
    "def compare_row_literals(table_name, old_year, new_year, ferc1_engine):\n",
    "    idx_cols = [\"row_number\", \"row_seq\"]\n",
    "    old_df = get_row_literals(table_name, old_year, ferc1_engine).drop(columns=[\"row_status\", \"sched_table_name\"])\n",
    "    new_df = get_row_literals(table_name, new_year, ferc1_engine).drop(columns=[\"row_status\", \"sched_table_name\"])\n",
    "    merged_df = (\n",
    "        pd.merge(old_df, new_df, on=idx_cols, suffixes=[\"_old\", \"_new\"], how=\"outer\")\n",
    "        .set_index(idx_cols)\n",
    "    )\n",
    "    merged_df = (\n",
    "        merged_df.loc[:, merged_df.columns.sort_values()]\n",
    "        .assign(match=lambda x: x.row_literal_new == x.row_literal_old)\n",
    "    )\n",
    "    return merged_df \n",
    "\n",
    "def check_all_row_years(table_name, ferc1_engine):\n",
    "    years = list(range(min(pc.WORKING_PARTITIONS[\"ferc1\"][\"years\"]), max(pc.WORKING_PARTITIONS[\"ferc1\"][\"years\"])))\n",
    "    years.sort()\n",
    "    for old_year in years:\n",
    "        compared = compare_row_literals(table_name, old_year, old_year+1, ferc1_engine)\n",
    "        if not compared.match.all():\n",
    "            logger.error(f\"  * CHECK: {old_year} vs. {old_year+1}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recent_year_comparison = compare_row_literals(\"f1_plant_in_srvce\", max(pc.WORKING_PARTITIONS[\"ferc1\"][\"years\"]) - 1, max(pc.WORKING_PARTITIONS[\"ferc1\"][\"years\"]), ferc1_engine)\n",
    "      \n",
    "unmatched_recent_rows = recent_year_comparison[~recent_year_comparison.match]\n",
    "if len(unmatched_recent_rows) > 0:\n",
    "    print(\"HEY!... check most recent row mappings!\")\n",
    "    display(recent_year_comparison[~recent_year_comparison.match])\n",
    "else:\n",
    "    print(\"Recent row mappings look consistent. No need to change anything.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "row_mapped_tables = [\n",
    "    \"f1_dacs_epda\",         # Depreciation data.\n",
    "    # \"f1_edcfu_epda\",      # Additional depreciation data. Not yet row mapped\n",
    "    # \"f1_acb_epda\",        # Additional depreciation data. Not yet row mapped\n",
    "    \"f1_elc_op_mnt_expn\",   # Electrical operating & maintenance expenses.\n",
    "    \"f1_elctrc_oper_rev\",   # Electrical operating revenues.\n",
    "    # \"f1_elc_oper_rev_nb\", # Additional electric operating revenues. One-line table. Not yet row mapped.\n",
    "    \"f1_income_stmnt\",      # Utility income statements.\n",
    "    # \"f1_incm_stmnt_2\",    # Additional income statement info. Not yet row mapped.\n",
    "    \"f1_plant_in_srvce\",    # Utility plant in service, by FERC account number.\n",
    "    \"f1_sales_by_sched\",    # Electricity sales by rate schedule -- it's a mess.\n",
    "]\n",
    "\n",
    "row_mapped_dfs = {t: pd.read_sql(t, ferc1_engine) for t in row_mapped_tables}\n",
    "for tbl in row_mapped_tables:\n",
    "    print(f\"{tbl}:\")\n",
    "    check_all_row_years(tbl, ferc1_engine)\n",
    "    print(\"\\n\", end=\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compare_row_literals(\"f1_plant_in_srvce\", max(pc.DATA_YEARS[\"ferc1\"]) - 1, max(pc.DATA_YEARS[\"ferc1\"]), ferc1_engine)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Identify Missing Respondents\n",
    "* Some FERC 1 respondents appear in the data tables, but not in the `f1_respondent_id` table.\n",
    "* During the database cloning process we create dummy entries for these respondents to ensure database integrity.\n",
    "* Some of these missing respondents can be identified based on the data they report.\n",
    "* For instance, `f1_respondent_id==519` reports two plants in the `f1_steam` table, named \"Kuester\" & \"Mihm\".\n",
    "* Searching for those plant names in the EIA 860 data (and Google) reveals those plants are owned by Upper Michigan Energy Resources Company (`utility_id_eia==61029`).\n",
    "* These \"PUDL Determined\" respondent names are stored in the `pudl.extract.ferc1.PUDL_RIDS` dictionary, and used to populate the `f1_respondent_id` table when they're available.\n",
    "* However, since many plants are owned by multiple utilities, we need to identify a utility that matches *all* of the reported plant names, hopefully uniquely.\n",
    "* The following functions help us identify that kind of utility."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_util_from_plants(pudl_out, patterns, display=False):\n",
    "    \"\"\"\n",
    "    Find any utilities associated with a list patterns for matching plant names.\n",
    "    \n",
    "    Args:\n",
    "        pudl_out (pudl.output.pudltabl.PudlTable): A PUDL Output Object.\n",
    "        patterns (iterable of str): Collection of patterns with which to match\n",
    "            the names of power plants in the EIA 860. E.g. \".*Craig.*\".\n",
    "        display (bool): Whether or not to display matching records for\n",
    "            debugging and refinement purposes.\n",
    "\n",
    "    Returns:\n",
    "        pandas.DataFrame: All records from the utilities_eia860 table\n",
    "        pertaining to the utilities identified as being associated with\n",
    "        plants that matched all of the patterns.\n",
    "\n",
    "    \"\"\"\n",
    "    own_eia860 = pudl_out.own_eia860()\n",
    "    plants_eia860 = pudl_out.plants_eia860()\n",
    "    \n",
    "    util_ids = []\n",
    "    for pat in patterns:\n",
    "        owners_df = own_eia860[own_eia860.plant_name_eia.fillna(\"\").str.match(pat, case=False)]\n",
    "        plants_df = plants_eia860[plants_eia860.plant_name_eia.fillna(\"\").str.match(pat, case=False)]\n",
    "        if display:\n",
    "            print(f\"Pattern: \\\"{pattern}\\\"\")\n",
    "            display(owners_df)\n",
    "            display(plants_df)\n",
    "        util_ids.append(set.union(set(owners_df.owner_utility_id_eia), set(plants_df.utility_id_eia)))\n",
    "        \n",
    "    util_ids = set.intersection(*util_ids)\n",
    "    utils_eia860 = pudl_out.utils_eia860()\n",
    "\n",
    "    return utils_eia860[utils_eia860.utility_id_eia.isin(util_ids)]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Missing Respondents\n",
    "* This will show all the as of yet unidentified respondents\n",
    "* You can then use these respondent IDs to search through other tables for identifying information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1_respondent_id = pd.read_sql(\"f1_respondent_id\", ferc1_engine)\n",
    "missing_respondent_ids = f1_respondent_id[f1_respondent_id.respondent_name.str.contains(\"Missing Respondent\")].respondent_id.unique()\n",
    "missing_respondent_ids"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Utility identification example using Plants\n",
    "* Let's use `respondent_id==529` which was identified as Tri-State Generation & Transmission in 2019\n",
    "* Searching for that `respondent_id` in all of the plant-related tables we find the following plants:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "    pudl.glue.ferc1_eia.get_db_plants_ferc1(pudl_settings, years=pc.DATA_YEARS[\"ferc1\"])\n",
    "    .query(\"utility_id_ferc1==529\")\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a list of patterns based on plant names\n",
    "* Pretend this respondent hadn't already been identified\n",
    "* Generate a list of plant name patterns based on what we see here\n",
    "* Use the above function `get_utils_from_plants` to identify candidate utilities involved with those plants, in the EIA data.\n",
    "* Note that the list of patterns doesn't need to be exhaustive -- just enough to narrow down to a single utility."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pudl_out = pudl.output.pudltabl.PudlTabl(pudl_engine=pudl_engine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_util_from_plants(\n",
    "    pudl_out,\n",
    "    patterns=[\n",
    "    \".*laramie.*\",\n",
    "    \".*craig.*\",\n",
    "    \".*escalante.*\",\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Another example `with respondent_id==519`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "    pudl.glue.ferc1_eia.get_db_plants_ferc1(pudl_settings, years=pc.DATA_YEARS[\"ferc1\"])\n",
    "    .query(\"utility_id_ferc1==519\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_util_from_plants(\n",
    "    pudl_out,\n",
    "    patterns=[\n",
    "    \".*kuester.*\",\n",
    "    \".*mihm.*\",\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### And again with `respondent_id==531`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "    pudl.glue.ferc1_eia.get_db_plants_ferc1(pudl_settings, years=pc.DATA_YEARS[\"ferc1\"])\n",
    "    .query(\"utility_id_ferc1==531\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_util_from_plants(\n",
    "    pudl_out,\n",
    "    patterns = [\n",
    "    \".*leland.*\",\n",
    "    \".*antelope.*\",\n",
    "    \".*dry fork.*\",\n",
    "    \".*laramie.*\",\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What about missing respondents in the Plant in Service table?\n",
    "* There are a couple of years worth of plant in service data associated with unidentified respondents.\n",
    "* Unfortunately the plant in service table doesn't have a lot of identifying information.\n",
    "* The same is true of the `f1_dacs_epda` depreciation table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1_plant_in_srvce = pd.read_sql_table(\"f1_plant_in_srvce\", ferc1_engine)\n",
    "f1_plant_in_srvce[f1_plant_in_srvce.respondent_id.isin(missing_respondent_ids)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Identify new strings for cleaning\n",
    "* Several FERC 1 fields contain freeform strings that should have a controlled vocabulary imposed on them.\n",
    "* This function help identify new, unrecognized strings in those fields each year.\n",
    "* Use regular expressions to identify collections of new, related strings, and add them to the appropriate string cleaning dictionary entry in `pudl.transform.ferc1`.\n",
    "* then re-run the cell with new search terms, until everything left is impossible to confidently categorize."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_me = [\n",
    "    {\"table\": \"f1_fuel\",  \"field\": \"fuel\",       \"strdict\": pudl.transform.ferc1.FUEL_STRINGS},\n",
    "    {\"table\": \"f1_fuel\",  \"field\": \"fuel_unit\",  \"strdict\": pudl.transform.ferc1.FUEL_UNIT_STRINGS},\n",
    "    {\"table\": \"f1_steam\", \"field\": \"plant_kind\", \"strdict\": pudl.transform.ferc1.PLANT_KIND_STRINGS},\n",
    "    {\"table\": \"f1_steam\", \"field\": \"type_const\", \"strdict\": pudl.transform.ferc1.CONSTRUCTION_TYPE_STRINGS},\n",
    "]\n",
    "\n",
    "for kwargs in clean_me:\n",
    "    unmapped_strings = pudl.helpers.find_new_ferc1_strings(ferc1_engine=ferc1_engine, **kwargs)\n",
    "    print(f\"{len(unmapped_strings)} unmapped {kwargs['field']} strings found.\")\n",
    "    if unmapped_strings:\n",
    "        display(unmapped_strings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "toc-autonumbering": true
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
